# Article Summarizer: Automated News Analysis Tool

## üë• Team Members

Thi Hong Nhung
Sayqin Rustamli

---

## 1. Project Overview

**Goal:**  
Create a tool that automates the process of finding, summarizing, and analyzing the sentiment of news articles related to a given topic.

**Motivation:**  
With the overwhelming amount of news published daily, it is difficult to quickly get a concise, unbiased overview of current events. Our tool helps users:

- Find related news from multiple sources
- Get concise summaries
- Understand the overall sentiment

---

## 2. Data & Sources

**Type of Data:**

- News articles (web scraping)
- Cross-sectional, real-time data

**Sources Used:**

- Google News (aggregator)
- Le Monde (French news)
- Le Figaro (French news)

**Why these sources?**

- Diversity of perspectives
- Reliable, up-to-date information
- French focus for demonstration

---

## Aper√ßu G√©n√©ral
Cette extension Chrome permet de r√©sumer automatiquement des articles provenant des sites d'actualit√©s fran√ßaises (lemonde.fr, lefigaro.fr), d'analyser le sentiment et de sugg√©rer des articles connexes, en utilisant l'API OpenAI. Le syst√®me comprend quatre composants principaux :
- **Frontend (Extension)** : Interface utilisateur et gestion des interactions.
- **Script de Contenu** : Extraction du contenu des articles depuis les pages web.
- **Backend (Serveur Flask)** : Traitement principal (r√©sum√©, analyse de sentiment).
- **Int√©gration IA** : Connexion √† l'API OpenAI pour l'analyse s√©mantique.

### 1. `manifest.json` - Configuration de l'Extension
```json
{
    "manifest_version": 3,
    "name": "Article Summarizer",
    "version": "1.0",
    "description": "R√©sume des articles...",
    "permissions": ["activeTab", "scripting", "storage"],
    "host_permissions": ["*://*.lemonde.fr/*", "*://*.lefigaro.fr/*"],
    "action": {
        "default_popup": "src/popup.html"
    }
}
```

Objectif :

D√©finir les autorisations et les param√®tres de base de l'extension.

Permettre l'acc√®s aux domaines cibles (lemonde.fr, lefigaro.fr).

## 2. `content.js` - Extraction du Contenu

``` javascript
function extractArticleContent() {
    const possibleContentSelectors = [
        "article", 
        ".article-content",
        // S√©lecteurs sp√©cifiques pour lemonde.fr/lefigaro.fr
    ];
    // Logique de d√©tection du contenu principal...
}
```
Fonctionnalit√©s :

Utilise 15+ s√©lecteurs CSS pour identifier le contenu principal.

Priorise les √©l√©ments avec le plus de texte (contenu probable).

M√©thode de repli : agr√©gation des paragraphes longs (>100 caract√®res).

## 3. Interface Utilisateur (popup.html/popup.js)

```html
<!-- Extrait de popup.html -->
<div id="results">
    <h3>R√©sum√©</h3>
    <div id="summary"></div>
    <h3>Sentiment</h3>
    <div id="sentiment" class="neutral"></div>
</div>
```
- Flux d'Ex√©cution :
L'utilisateur clique sur "R√©sumer l'article".
- Le script popup.js :
    Affiche un loader.
    Appelle content.js pour extraire le contenu.
    Envoie les donn√©es au backend via fetch().
    Affiche les r√©sultats (r√©sum√©, sentiment, articles connexes).
- Gestion des Erreurs :
    Messages contextuels pour les erreurs CORS/API.
    Journalisation des erreurs dans la console.

## 4. ` app.py ` - Backend et Traitement IA

``` python 
@app.route('/summarize', methods=['POST'])
def summarize_article():
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "Assistant de r√©sum√©..."},
            {"role": "user", "content": f"Titre: {title}\nContenu: {truncated_content}"}
        ]
    )
    # Extraction du r√©sum√© et du sentiment
```
- Fonctionnalit√©s principales :

R√©ception du contenu depuis l'extension

Appel √† l'API OpenAI avec un prompt structur√©

Extraction des informations depuis la r√©ponse :

R√©sum√© concis (limit√© √† 150 mots)

Sentiment global (Positif/N√©gatif/Neutre)

- Optimisations :

Limitation de la longueur du contenu (4000 caract√®res) pour respecter les limites de tokens

Journalisation d√©taill√©e des erreurs

## 5. ` requirements.txt ` - D√©pendances Python
``` python
flask==2.2.3
openai>=1.0.0
beautifulsoup4==4.11.2
```
- Objectif :

D√©finir les d√©pendances n√©cessaires au backend

Flask pour le serveur web

BeautifulSoup4 pour le scraping d'articles connexes

### Flux de Donn√©es Global

## Image



- Solutions Techniques Remarquables.

1 . Multiplateforme d'actualit√©s :

Prise en charge simultan√©e de lemonde.fr et lefigaro.fr

Syst√®me de s√©lecteurs CSS redondants pour am√©liorer la compatibilit√©

2. Analyse de Sentiment Intelligente :

Normalisation des r√©sultats en trois cat√©gories

Codage couleur pour l'affichage (vert/rouge/gris)

3. Actualit√©s Connexes en Temps R√©el :
``` python
 def search_lemonde(query):
    formatted_query = query.replace(" ", "+")
    url = f"https://www.lemonde.fr/recherche/?search_keywords={formatted_query}"
    # Parsing des r√©sultats
```

Scraping direct depuis les moteurs de recherche des sites

Gestion des URL relatives et des param√®tres complexes


## Installation et Test

1 . Installation et Test

``` bash
chrome://extensions ‚Üí Charger l'extension non empaquet√©e (dossier contenant manifest.json)
```
2. D√©marrage du backend :

``` bash
pip install -r requirements.txt
export OPENAI_API_KEY='votre-cl√©'
python app.py
```
3. Naviguer sur lemonde.fr/lefigaro.fr et utiliser l'extension

Ce document pr√©sente une explication structur√©e en fran√ßais professionnel,
mettant en avant les aspects techniques tout en restant accessible pour un public sp√©cialis√©. 
Il int√®gre des termes techniques appropri√©s et d√©crit clairement les interactions entre les composants du syst√®me.
